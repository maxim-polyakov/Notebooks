{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот набор данных представляет собой запись о 7 распространенных различных видах рыб, продаваемых на рыбном рынке. С помощью этого набора данных можно обучить модель, которая будет предсказывать **вес рыбы**.\n",
    "\n",
    "- Weight - weight of fish in Gram g\n",
    "- Length1 - vertical length in cm\n",
    "- Length2 - diagonal length in cm\n",
    "- Length3 - cross length in cm\n",
    "- Height - height in cm\n",
    "- Width - diagonal width in cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Импортируйте файл Fish.csv, записав в переменную **df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Length1</th>\n",
       "      <th>Length2</th>\n",
       "      <th>Length3</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bream</td>\n",
       "      <td>242.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>25.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.5200</td>\n",
       "      <td>4.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bream</td>\n",
       "      <td>290.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>31.2</td>\n",
       "      <td>12.4800</td>\n",
       "      <td>4.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bream</td>\n",
       "      <td>340.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.3778</td>\n",
       "      <td>4.6961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bream</td>\n",
       "      <td>363.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>12.7300</td>\n",
       "      <td>4.4555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bream</td>\n",
       "      <td>430.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.4440</td>\n",
       "      <td>5.1340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>12.2</td>\n",
       "      <td>11.5</td>\n",
       "      <td>12.2</td>\n",
       "      <td>13.4</td>\n",
       "      <td>2.0904</td>\n",
       "      <td>1.3936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>13.4</td>\n",
       "      <td>11.7</td>\n",
       "      <td>12.4</td>\n",
       "      <td>13.5</td>\n",
       "      <td>2.4300</td>\n",
       "      <td>1.2690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>12.2</td>\n",
       "      <td>12.1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>2.2770</td>\n",
       "      <td>1.2558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>19.7</td>\n",
       "      <td>13.2</td>\n",
       "      <td>14.3</td>\n",
       "      <td>15.2</td>\n",
       "      <td>2.8728</td>\n",
       "      <td>2.0672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Smelt</td>\n",
       "      <td>19.9</td>\n",
       "      <td>13.8</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>2.9322</td>\n",
       "      <td>1.8792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Species  Weight  Length1  Length2  Length3   Height   Width\n",
       "0     Bream   242.0     23.2     25.4     30.0  11.5200  4.0200\n",
       "1     Bream   290.0     24.0     26.3     31.2  12.4800  4.3056\n",
       "2     Bream   340.0     23.9     26.5     31.1  12.3778  4.6961\n",
       "3     Bream   363.0     26.3     29.0     33.5  12.7300  4.4555\n",
       "4     Bream   430.0     26.5     29.0     34.0  12.4440  5.1340\n",
       "..      ...     ...      ...      ...      ...      ...     ...\n",
       "154   Smelt    12.2     11.5     12.2     13.4   2.0904  1.3936\n",
       "155   Smelt    13.4     11.7     12.4     13.5   2.4300  1.2690\n",
       "156   Smelt    12.2     12.1     13.0     13.8   2.2770  1.2558\n",
       "157   Smelt    19.7     13.2     14.3     15.2   2.8728  2.0672\n",
       "158   Smelt    19.9     13.8     15.0     16.2   2.9322  1.8792\n",
       "\n",
       "[159 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Fish.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Вывести первые пять строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Length1</th>\n",
       "      <th>Length2</th>\n",
       "      <th>Length3</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bream</td>\n",
       "      <td>242.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>25.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>11.5200</td>\n",
       "      <td>4.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bream</td>\n",
       "      <td>290.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>31.2</td>\n",
       "      <td>12.4800</td>\n",
       "      <td>4.3056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bream</td>\n",
       "      <td>340.0</td>\n",
       "      <td>23.9</td>\n",
       "      <td>26.5</td>\n",
       "      <td>31.1</td>\n",
       "      <td>12.3778</td>\n",
       "      <td>4.6961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bream</td>\n",
       "      <td>363.0</td>\n",
       "      <td>26.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>33.5</td>\n",
       "      <td>12.7300</td>\n",
       "      <td>4.4555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bream</td>\n",
       "      <td>430.0</td>\n",
       "      <td>26.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.4440</td>\n",
       "      <td>5.1340</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Species  Weight  Length1  Length2  Length3   Height   Width\n",
       "0   Bream   242.0     23.2     25.4     30.0  11.5200  4.0200\n",
       "1   Bream   290.0     24.0     26.3     31.2  12.4800  4.3056\n",
       "2   Bream   340.0     23.9     26.5     31.1  12.3778  4.6961\n",
       "3   Bream   363.0     26.3     29.0     33.5  12.7300  4.4555\n",
       "4   Bream   430.0     26.5     29.0     34.0  12.4440  5.1340"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Выведите размер датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Вывести общую информацию о датафрейме при помощи метода info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Вывести основные описательные статистики для числовых и категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Постройте тепловую карту для оценки **корреляции признаков**, что можно сказать на основании графика?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Удалите скоррелированные числовые признаки, где корреляция больше 0.9, при помощи кода ниже, где:\n",
    "- df - исходный датасет\n",
    "- to_drop - колонки, которые необходимо удалить\n",
    "\n",
    "**Результат запишите в переменную df_clean**, переменную df в данном случае оставьте без изменений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_matrix = # ваш код.drop(['Weight'], axis=1).corr().abs()\n",
    "\n",
    "upper_tri = cor_matrix.where(\n",
    "    np.triu(np.ones(cor_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "to_drop = [\n",
    "    column for column in upper_tri.columns if any(upper_tri[column] > 0.9)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Проанализируйте **целевую переменную Weight в df_clean**, что вы можете сказать о распределении? Нормально ли оно? проверьте при помощи стат метода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Если распределение не нормальное, то **прологарифмируйте**  таргет Weight с **добавлением внутри единицы**, **записав значения в новую колонку Weight_log** в переменнной df_clean\n",
    "\n",
    "Проверьте, стало ли распределение нормальным при помощи стат метода.\n",
    "\n",
    "> Если распределение не стало полностью нормальным, то ничего страшного. Для таких целей обычно используют функцию потерь устойчивую к выбросам, но мы возьмем прологарифмированную целевую переменную и представим, что распрееление все-так стало нормальным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Создайте новую переменную **df_label**, присвойте ей трансформированный датасет df_clean при помощи One-hot кодирования (лучше использовать pandas.get_dummies() для бинаризации)\n",
    "\n",
    "Примените drop_first = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11) Разбиение данных на train/test\n",
    "\n",
    "- Разбейте данные на тренировочные и тестовые test_size=0.25\n",
    "- Установите константу RAND = 10 в самом начале и используйте далее как random_state\n",
    "- **Не забывайте про стандартизацию**\n",
    "- Не забывайте, что нужно для записи в переменную X удалить целевые переменные 'Weight', 'Weight_log'\n",
    "- Если вы логарифмировали y_test, то незабудьте создать к примеру новую переменную y_test_exp (произвести **ПОТЕНЦИОНИРОВАНИЕ**), чтобы правильно анализировать значения метрик\n",
    "\n",
    "> Как сделать потенционирование? При условии, что при логарифмировании добавляли единицу\n",
    "```python\n",
    "y_test_exp = np.exp(y_test) - 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12) Необходимо реализовать алгоритм Linear Regression при помощи метода оптимизации **стохастический градиентный спуск**\n",
    "\n",
    "Необходимо взять пример из лекции, где реализована линейная регрессия без использования sklearn, и немного поменять алгоритм.\n",
    "\n",
    "- Не забываем, что нам нет необходимости суммировать результат по всей выборке! Смотреть формулу из презентации\n",
    "- А также будьте аккуратны при вычитании антиградиента (не будет нормирования на всю длину X)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_adjusted(y_true: np.ndarray, y_pred: np.ndarray,\n",
    "                X_test: np.ndarray) -> float:\n",
    "    \"\"\"Коэффициент детерминации (множественная регрессия)\"\"\"\n",
    "    N_objects = len(y_true)\n",
    "    N_features = X_test.shape[1]\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return 1 - (1 - r2) * (N_objects - 1) / (N_objects - N_features - 1)\n",
    "\n",
    "\n",
    "def mpe(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"Mean percentage error\"\"\"\n",
    "    return np.mean((y_true - y_pred) / y_true) * 100\n",
    "\n",
    "\n",
    "def mape(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"Mean absolute percentage error\"\"\"\n",
    "    return np.mean(np.abs((y_pred - y_true) / y_true)) * 100\n",
    "\n",
    "\n",
    "def wape(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"Weighted Absolute Percent Error\"\"\"\n",
    "    return np.sum(np.abs(y_pred - y_true)) / np.sum(y_true) * 100\n",
    "\n",
    "\n",
    "def huber_loss(y_true: np.ndarray, y_pred: np.ndarray, delta: float = 1.345):\n",
    "    \"\"\"Функция ошибки Хьюбера\"\"\"\n",
    "    assert len(y_true) == len(y_pred), 'Разные размеры данных'\n",
    "    huber_sum = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if abs(y_true[i] - y_pred[i]) <= delta:\n",
    "            huber_sum += 0.5 * (y_true[i] - y_pred[i])**2\n",
    "        else:\n",
    "            huber_sum += delta * (abs(y_true[i] - y_pred[i]) - 0.5 * delta)\n",
    "    huber_sum /= len(y_true)\n",
    "    return huber_sum\n",
    "\n",
    "\n",
    "def logcosh(y_true: np.ndarray, y_pred: np.ndarray):\n",
    "    \"\"\"функция ошибки Лог-Кош\"\"\"\n",
    "    return np.sum(np.log(np.cosh(y_true - y_pred)))\n",
    "\n",
    "\n",
    "def rmsle(y_true: np.ndarray, y_pred: np.ndarray) -> np.float64:\n",
    "    \"\"\"\n",
    "    The Root Mean Squared Log Error (RMSLE) metric \n",
    "    Логаритмическая ошибка средней квадратичной ошибки\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_metrics(y_test: np.ndarray,\n",
    "                y_pred: np.ndarray,\n",
    "                X_test: np.ndarray,\n",
    "                name: str = None,\n",
    "                delta: float = 1.345):\n",
    "    \"\"\"Генерация таблицы с метриками\"\"\"\n",
    "    df_metrics = pd.DataFrame()\n",
    "\n",
    "    df_metrics['model'] = [name]\n",
    "\n",
    "    df_metrics['MAE'] = mean_absolute_error(y_test, y_pred)\n",
    "    df_metrics['MSE'] = mean_squared_error(y_test, y_pred)\n",
    "    df_metrics['RMSE'] = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    df_metrics['RMSLE'] = rmsle(y_test, y_pred)\n",
    "    df_metrics['R2 adjusted'] = r2_adjusted(y_test, y_pred, X_test)\n",
    "    # df_metrics['Huber_loss'] = huber_loss(y_test, y_pred, delta)\n",
    "    # df_metrics['Logcosh'] = logcosh(y_test, y_pred)\n",
    "    df_metrics['MPE_%'] = mpe(y_test, y_pred)\n",
    "    df_metrics['MAPE_%'] = mape(y_test, y_pred)\n",
    "    df_metrics['WAPE_%'] = wape(y_test, y_pred)\n",
    "\n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13) Обучите разработанную модель линейной регрессии с использованием следующих значений параметров на train выборке:\n",
    "    \n",
    "- learning_rate=0.001\n",
    "- eps=0.0000001\n",
    "- iters=4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14) Какие результаты по основным метрикам вы получили на test? Что можно сказать про модель?\n",
    "\n",
    "- Не забудьте преобразовать обратно целевую переменную (потенционирование) для анализа метрик (для y_test и y_predict), но **в обучении участвуют прологарифмированные данные**.\n",
    "\n",
    "- На какую метрику **более релевантно смотреть на основании распределения целевой перменной**?\n",
    "- На подобие как и в лекции, сделайте отдельный вывод метрик в DataFrame и запишите **результат в переменную metrics**\n",
    "- Если вы получили большие значения метрик (применимо и далее), проверьте, сделали ли вы потенционирование, а также проверьте сам алгоритм оптимизации внутри LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15) Сформируйте **таблицу DataFrame с расчитанными весами** для каждого из признаков на основании обученного ранее алгоритма:\n",
    "- где первый столбец **feature** - содержатся названия признаков\n",
    "- второй столбец **score** - содержатся значения весов перед соответстввующими признаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16) Примените стандартный метод для линейной регресии из **sklearn**, обучите модель на train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17) Какие результаты по основным метрикам вы получили на test?\n",
    "\n",
    "- Что можно сказать про модель?\n",
    "- Добавьте значения метрик по результатам работы линейной регрессии из sklearn в общий датасет с метриками **в переменную metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18) Сформируйте **таблицу DataFrame с расчитанными весами** для каждого из признаков на основании обученного ранее алгоритма:\n",
    "- где первый столбец **feature** - содержатся названия признаков\n",
    "- второй столбец **score** - содержатся значения весов перед соответстввующими признаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Борьба с переобучением"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19) Примените Ridge, Lasso и ElasticNet (sklearn.linear_model) регуляризации при alpha=0.001, какие результы для каждой модели вы получили на основании предыдущих метрик?\n",
    "\n",
    "Аналогично добавьте метрики по результатам работы алгоритмов в переменную metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20) На основании распределения (даже после преобразования) используйте необходимую метрику или неск метрик, и напишите, какая из моделей была лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш ответ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кросс-валидация с Holdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21) Обучите **наилучшую выбранную модель** из прошлых заданий при помощи **кросс-валидации KFold** с 3мя фолдами на holdout (пример в лекции).\n",
    "\n",
    "- Брать обученную модель НЕ НУЖНО, необходимо внутри кросс-валидации ЗАНОВО создавать объект экземпляра класса модели с параметрами, которые у нее были\n",
    "- Не забывайте про ранее зафиксированный **random_state**\n",
    "- В качестве метрики возьмите среднюю абсолютную ошибку **mean_absolute_error**\n",
    "- На каждом фолде подсчитать **значение MAE на validation** данных и **вывести**\n",
    "- Не забывать про обратное преобразование целевой переменной из логарифма (**потенционирование**), иначе будут очень большие значения метрик\n",
    "- Выведите по итогу **среднее значение MAE** полученное на всех фолдах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22) Получите **предсказанные значения на Holdout** данных при помощи усреднения значений, полученных на каждом фолде\n",
    "\n",
    "**Сравните** результат MAE на validation (OOF) и на test данных (Holdout)\n",
    "\n",
    "\n",
    "Подсказка:\n",
    "- для получения средних значений на Holdout используйте np.mean(np.column_stack(*), axis=1), если * - имеет тип список, а внутри тип np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23) Добавьте в датасет с метриками **metrics** результаты обучения модели с **KFold на Holdout данных**.\n",
    "\n",
    "Где вы получили самые наилучшие результаты?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Компания, которая активно занимается Big Data и Data Science, хочет нанять специалистов по анализу данных среди людей, которые успешно проходят ее курсы. Многие люди регистрируются на обучение и компания хочет понимать, кто из этих кандидатов действительно хочет работать в компании после обучения или поиска новой работы, потому что это помогает снизить стоимость и время, а также повысить качество обучения, оптимизировать расписание курсов, понимать портрет кандидата. \n",
    "\n",
    "\n",
    "- enrolle_id - Уникальный идентификатор кандидата\n",
    "- city - Код города\n",
    "- city_ development _index - Индекс развития города (масштабированный)\n",
    "- gender - пол кандидата\n",
    "- relevent_experience - релевантный опыт кандидата\n",
    "- enrolled_university - тип обучения в университете (если был)\n",
    "- education_level - уровень образования кандидата\n",
    "- major_discipline - основная специальность по образованию\n",
    "- experience - общий стаж кандидата в годах\n",
    "- company_size - размер компании в работниках\n",
    "- company_type - тип работодателя\n",
    "- lastnewjob - дельта в годах между предыдущей и текущей работах\n",
    "- training_hours - кол-во завершенных часов обучения\n",
    "- target 0 – Не ищу новую работу\n",
    "- target 1 – Ищу новую работу\n",
    "\n",
    "\n",
    "\n",
    "Спрогнозировать вероятность того, что кандидат будет искать новую работу или будет работать в компании (0 - не ищу новую работу). target - целевая переменная"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24) Импортируйте файл aug_train.csv, записав в переменную **df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25) Вывести первые пять строк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26) Выведите размер датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27) Вывести общую информацию о датафрейме при помощи метода info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28) Вывести основные описательные статистики для числовых и категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "29) Проанализировать кол-во пропусков, а также посмотреть сколько это в процентах от размера датасета (кол-ва строк)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30) Заполните пропусками датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31) Посмотрите на целевую переменную **target** при помощи seaborn.countplot. Какое соотношение классов? Есть ли дисбаланс?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32) Создайте новую переменную **df_label**, присвойте ей трансформированный датасет df при помощи One-hot кодирования (лучше использовать pandas.get_dummies() для бинаризации)\n",
    "\n",
    "- Примените drop_first = True\n",
    "- Не забудьте удалить индексы ('enrollee_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_test, y_pred, y_score, name):\n",
    "    df_metrics = pd.DataFrame()\n",
    "\n",
    "    df_metrics['model'] = [name]\n",
    "\n",
    "    # Основные метрики для задачи классификации\n",
    "    df_metrics['Accuracy'] = accuracy_score(y_test, y_pred)\n",
    "    df_metrics['ROC_AUC'] = roc_auc_score(y_test, y_score[:, 1])\n",
    "    df_metrics['Precision'] = precision_score(y_test, y_pred)\n",
    "    df_metrics['Recall'] = recall_score(y_test, y_pred)\n",
    "    df_metrics['f1'] = f1_score(y_test, y_pred)\n",
    "    df_metrics['Logloss'] = log_loss(y_test, y_score)\n",
    "\n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "33) Разбиение данных на train/test\n",
    "\n",
    "- Разбейте данные на тренировочные и тестовые test_size=0.25\n",
    "- Установите константу RAND = 10 в самом начале и используйте далее как random_state\n",
    "- Не забывайте про стандартизацию\n",
    "- Установите stratify=y\n",
    "- Не забывайте, что нужно для записи данных в переменную X удалить целевую переменную target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "34) Примените стандартный метод для логистической регресии из **sklearn**\n",
    "\n",
    "- Обучите модель на стандартизованных train и получите предсказанные значения на test\n",
    "- Используйте для baseline параметр **class_weight и random_state**\n",
    "- Сделайте отдельный вывод метрик в DataFrame и запишите **результат в переменную metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "35) Постройте график кривой ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "36) Найдите параметры для LogisticRegression, используя StratifiedKFold с 3 фолдами, при помощи **GridSearch**\n",
    "\n",
    "- Метрика для оптимизации scoring = 'roc_auc'\n",
    "\n",
    "- Нужно использовать такие параметры как: penalty, C, solver, l1_ratio\n",
    "\n",
    "- Не забудьте для StratifiedKFold зафиксировать random_state и class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "37) Выведите наилучшие значения метрик и параметры после обучения GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "38) Найдите параметры для LogisticRegression, используя StratifiedKFold с 3 фолдами, при помощи **RandomizedSearchCV**\n",
    "\n",
    "- Метрика для оптимизации scoring = 'roc_auc'\n",
    "\n",
    "- Нужно использовать такие параметры как: penalty, C, solver, l1_ratio\n",
    "\n",
    "- Не забудьте для StratifiedKFold зафиксировать random_state и class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "39) Выведите наилучшие значения метрик и параметры после обучения RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40) Обучение на фолдах на лучших параметрах\n",
    "\n",
    "- Далее используйте кросс-валидацию со стратификацией **StratifiedKFold с 3мя фолдами** как делали ранее\n",
    "- Не забудьте для StratifiedKFold зафиксировать **random_state**\n",
    "- Подайте на вход модели LogisticRegression() **наилучшие параметры**, полученные путем поиска по сетке (выбрать между параметрами GridSearchCV и RandomizedSearchCV по значениям метрик - атрибут *.best_score_)\n",
    "- В качестве метрики возьмите **ROC_AUC**\n",
    "- Не забывайте использовать стандартизованные данные \n",
    "- На каждом фолде подсчитать значение **ROC-AUC на validation** данных и **вывести**\n",
    "- Выведите по итогу **среднее значение ROC-AUC** полученное на всех фолдах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "41) Получите **предсказанные значения на Holdout** данных при помощи усреднения значений (для вероятностй) и моды (для меток классов), полученных при обучении на фолдах\n",
    "\n",
    "**Сравните** результат ROC-AUC на validation (OOF) и на test данных (Holdout)\n",
    "\n",
    "\n",
    "Подсказка:\n",
    "- для получения средних значений на Holdout используйте np.mean(np.column_stack(****), axis=1)\n",
    "- для получения моды на Holdout используйте stats.mode(np.column_stack(****), axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "42) Добавьте в датасет с метриками **metrics** результаты обучения модели с **StratifiedKFold на Holdout данных**.\n",
    "\n",
    "Где вы получили самые наилучшие результаты?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшились ли результаты на Holdout по сравнению c Baseline? **Если нет, попробуйте тщательнее подобрать значения в методах поиска по сетке и снова посмотрите результаты.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание со звездочкой\n",
    "\n",
    "Найти гиперпараметры для LogisticRegression при помощи **Optuna**, предварительно установив библиотеку. Использовать аналогичный подход с использованием кросс-валидации. Необходимо при помощи Optuna улучить результаты с прошлыми обученными моделями, только в этом случае задание засчитывается.\n",
    "\n",
    "Пример того как находить параметры и как получить итоговый результат:\n",
    "\n",
    "https://github.com/miracl1e6/nyc-taxi-trip-duration/blob/master/nyc-taxi-lgboost-lama.ipynb\n",
    "\n",
    "Дополнительные материалы, которые могут помочь разобраться:\n",
    "- https://optuna.org\n",
    "- https://github.com/optuna/optuna\n",
    "- https://coderzcolumn.com/tutorials/machine-learning/simple-guide-to-optuna-for-hyperparameters-optimization-tuning\n",
    "\n",
    "\n",
    "Пример как можно при разных регуляризаторах добавить условия:\n",
    "```python\n",
    "if param_grid['solver'] in ['sag', 'lbfgs']:\n",
    "        param_grid['penalty'] = trial.suggest_categorical(\"penalty\", ['l2', 'none'])\n",
    "        \n",
    "```\n",
    "\n",
    "- ‘newton-cg’ - [‘l2’, ‘none’]\n",
    "- ‘lbfgs’ - [‘l2’, ‘none’]\n",
    "- ‘liblinear’ - [‘l1’, ‘l2’]\n",
    "- ‘sag’ - [‘l2’, ‘none’]\n",
    "- ‘saga’ - [‘elasticnet’, ‘l1’, ‘l2’, ‘none’]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ваш код"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
