{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T21:43:25.858804Z",
     "start_time": "2024-06-17T21:43:25.850379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, BertTokenizer, BertForSequenceClassification, BertModel\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import psycopg2\n",
    "tqdm.pandas()\n",
    "\n",
    "device = torch.device('cpu')"
   ],
   "id": "4046a6612b6421b1",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T21:25:33.237834Z",
     "start_time": "2024-06-17T21:25:27.068496Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install psycopg2-binary",
   "id": "f551561e42008a08",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: psycopg2-binary in c:\\users\\maxim\\anaconda3\\lib\\site-packages (2.9.9)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Tokenizer():\n",
    "    \"\"\"\n",
    "\n",
    "    This class is created for a sample's tokenization.\n",
    "\n",
    "    \"\"\"\n",
    "    TOP_K = 20000\n",
    "    MAX_SEQUENCE_LENGTH = 33\n",
    "\n",
    "    def __init__(self, train_texts):\n",
    "        self.train_texts = train_texts\n",
    "        self.tokenizer = token(num_words=self.TOP_K)\n",
    "\n",
    "    def train_tokenize(self):\n",
    "        max_length = len(max(self.train_texts, key=len))\n",
    "        self.max_length = min(max_length, self.MAX_SEQUENCE_LENGTH)\n",
    "        self.tokenizer.fit_on_texts(self.train_texts)\n",
    "\n",
    "    def vectorize_input(self, tweets):\n",
    "        tweets = self.tokenizer.texts_to_sequences(tweets)\n",
    "        tweets = b(tweets, maxlen=self.max_length, truncating='post', padding='post')\n",
    "        return tweets"
   ],
   "id": "619ca0556f6eab9b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T21:51:10.708714Z",
     "start_time": "2024-06-17T21:51:09.330216Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f8a2b782045dcdd6",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T21:25:34.729480Z",
     "start_time": "2024-06-17T21:25:34.722539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SELECT_HI = str('(select text, hi FROM train_sets.all_set_hi WHERE (hi=1) ORDER BY random() LIMIT 3000) ' +\n",
    "            'union all ' +\n",
    "            '(select text, hi FROM train_sets.all_set_none WHERE (hi=0) ORDER BY random() LIMIT 2000) ' +\n",
    "            'union all ' +\n",
    "            '(select text, hi FROM train_sets.all_set_thanks WHERE (hi=0) ORDER BY random() LIMIT 500) ' +\n",
    "            'union all ' +\n",
    "            '(select text, hi FROM train_sets.all_set_trash WHERE (hi=0) ORDER BY random() LIMIT 500)')"
   ],
   "id": "ac1eff2f6befcdd",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T21:51:18.203718Z",
     "start_time": "2024-06-17T21:51:16.555332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conn_remote = psycopg2.connect('postgres://postgres:gaTResKPJX25@ep-round-paper-091468.us-east-2.aws.neon.tech/BotsMemory')\n",
    "train = pd.read_sql(SELECT_HI, conn_remote)\n",
    "train.text = train.text.astype(str)\n",
    "df = pd.concat([train])\n",
    "df"
   ],
   "id": "af32a690faf3a83e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maxim\\AppData\\Local\\Temp\\ipykernel_11028\\2571229542.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  train = pd.read_sql(SELECT_HI, conn_remote)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                           text  hi\n",
       "0                       дратуть   1\n",
       "1                            ку   1\n",
       "2                         жарко   1\n",
       "3                         жарко   1\n",
       "4                         жарко   1\n",
       "...                         ...  ..\n",
       "2159                     трипер   0\n",
       "2160  твой рот выебывать гандон   0\n",
       "2161              спидозный пес   0\n",
       "2162       поймать очень больно   0\n",
       "2163                     залупа   0\n",
       "\n",
       "[2164 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>дратуть</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ку</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>жарко</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>жарко</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>жарко</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>трипер</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>твой рот выебывать гандон</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>спидозный пес</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>поймать очень больно</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>залупа</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2164 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T21:51:21.719635Z",
     "start_time": "2024-06-17T21:51:21.706671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train.text = train.text.astype(str)\n",
    "target = 'hi'\n",
    "df = df.drop(columns='hi')\n",
    "df = pd.concat([train])\n",
    "texts = df[~df[target].isna()]\n",
    "labels = train[target].astype(int)\n",
    "train = train.drop_duplicates()\n",
    "train"
   ],
   "id": "a669c9c796d9ce36",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                   text  hi\n",
       "0                                               дратуть   1\n",
       "1                                                    ку   1\n",
       "2                                                 жарко   1\n",
       "7     привет сегодня отпускать сотрудник дом неработ...   1\n",
       "8                                                привет   1\n",
       "...                                                 ...  ..\n",
       "2154                                          мокрощелк   0\n",
       "2156                        девушка красота мир спасать   0\n",
       "2159                                             трипер   0\n",
       "2161                                      спидозный пес   0\n",
       "2163                                             залупа   0\n",
       "\n",
       "[585 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>hi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>дратуть</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ку</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>жарко</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>привет сегодня отпускать сотрудник дом неработ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>привет</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>мокрощелк</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2156</th>\n",
       "      <td>девушка красота мир спасать</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>трипер</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>спидозный пес</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>залупа</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>585 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T22:00:00.242363Z",
     "start_time": "2024-06-17T22:00:00.234401Z"
    }
   },
   "cell_type": "code",
   "source": "train_texts, val_texts, train_labels, val_labels = train_test_split(texts, labels, test_size=0.2, random_state=42)",
   "id": "61cd395cb3f85e36",
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T22:00:01.113583Z",
     "start_time": "2024-06-17T22:00:01.108584Z"
    }
   },
   "cell_type": "code",
   "source": "train_texts = train_texts.drop(columns='hi')",
   "id": "8226d8d6a4b240fe",
   "outputs": [],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T22:00:02.570886Z",
     "start_time": "2024-06-17T22:00:02.565747Z"
    }
   },
   "cell_type": "code",
   "source": "val_texts = val_texts.drop(columns='hi')",
   "id": "ec5e772cd7308cc2",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T22:00:05.928860Z",
     "start_time": "2024-06-17T22:00:05.922611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TextClassificationDataset(df):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        return {'input_ids': encoding['input_ids'].flatten(), 'attention_mask': encoding['attention_mask'].flatten(), 'label': torch.tensor(label)}"
   ],
   "id": "bfdd7aa3d91636a7",
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T22:00:09.289762Z",
     "start_time": "2024-06-17T22:00:09.283352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self, bert_model_name, num_classes):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "\n",
    "def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs.pooler_output\n",
    "        x = self.dropout(pooled_output)\n",
    "        logits = self.fc(x)\n",
    "        return logits"
   ],
   "id": "51a92585fc5d7c3c",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T22:00:11.881348Z",
     "start_time": "2024-06-17T22:00:11.875954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model, data_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    for batch in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()"
   ],
   "id": "a4a3e069feee2a83",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T22:00:12.834043Z",
     "start_time": "2024-06-17T22:00:12.827978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "            actual_labels.extend(labels.cpu().tolist())\n",
    "    return accuracy_score(actual_labels, predictions), classification_report(actual_labels, predictions)"
   ],
   "id": "3cf433a5721ddc91",
   "outputs": [],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T22:00:14.502589Z",
     "start_time": "2024-06-17T22:00:14.496965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_sentiment(text, model, tokenizer, device, max_length=128):\n",
    "    model.eval()\n",
    "    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "    return \"positive\" if preds.item() == 1 else \"negative\""
   ],
   "id": "ef8ed39e49c70449",
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T22:00:15.210421Z",
     "start_time": "2024-06-17T22:00:15.205420Z"
    }
   },
   "cell_type": "code",
   "source": [
    " bert_model_name = 'bert-base-uncased'\n",
    " num_classes = 2\n",
    " max_length = 128\n",
    " batch_size = 16\n",
    " num_epochs = 4\n",
    " learning_rate = 2e-5"
   ],
   "id": "cc28c3e01ef4d445",
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T22:07:43.870153Z",
     "start_time": "2024-06-17T22:07:43.212238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(bert_model_name)\n",
    "train_dataset = TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\n",
    "val_dataset = TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
   ],
   "id": "130b31cc6c8e6833",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[72], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m BertTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(bert_model_name)\n\u001B[1;32m----> 2\u001B[0m train_dataset \u001B[38;5;241m=\u001B[39m TextClassificationDataset(train_texts, train_labels, tokenizer, max_length)\n\u001B[0;32m      3\u001B[0m val_dataset \u001B[38;5;241m=\u001B[39m TextClassificationDataset(val_texts, val_labels, tokenizer, max_length)\n\u001B[0;32m      4\u001B[0m train_dataloader \u001B[38;5;241m=\u001B[39m DataLoader(train_dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mTypeError\u001B[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T22:06:08.693218Z",
     "start_time": "2024-06-17T22:06:08.684074Z"
    }
   },
   "cell_type": "code",
   "source": "train_labels",
   "id": "ecb144165fef276e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1949    0\n",
       "1132    1\n",
       "381     1\n",
       "1247    1\n",
       "630     1\n",
       "       ..\n",
       "1638    0\n",
       "1095    1\n",
       "1130    1\n",
       "1294    1\n",
       "860     1\n",
       "Name: hi, Length: 1731, dtype: int32"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T21:44:14.141849Z",
     "start_time": "2024-06-17T21:43:31.544673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BERTClassifier(bert_model_name, num_classes).to(device)"
   ],
   "id": "d3762dc81ac24688",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "88a9e0e3321a43f381648f8df2d0399b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T22:05:37.007377Z",
     "start_time": "2024-06-17T22:05:36.998967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "total_steps = len(train_texts) * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)"
   ],
   "id": "a4472e00994d7346",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maxim\\anaconda3\\Lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T22:05:44.032520Z",
     "start_time": "2024-06-17T22:05:44.026125Z"
    }
   },
   "cell_type": "code",
   "source": "total_steps",
   "id": "ecaffd28d12f051f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6924"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "10cb8feccc9a8fda"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
